{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKj4DJdIn7D/k4DeWgmG7R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anush-Amin/Data-Analysis/blob/main/PySpark_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b8jmAjwb_RI",
        "outputId": "f56a49a0-339d-43d9-f8b4-024c6519758b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=d64ace2e366b125f57932ac1fa3d80cd3621007fa2ceb53662346a916b6cd5c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "p2BDy5RlcXo1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
      ],
      "metadata": {
        "id": "0dLfaLRRceHx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the dataset\n",
        "df_pyspark = spark.read.option('header','true').csv('test1.csv')"
      ],
      "metadata": {
        "id": "RHZo7PBXcMZr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the schema similar to info() in pandas\n",
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_OSTBhecS1m",
        "outputId": "145066cd-45bd-4df5-c73f-8c44d47a2d93"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name : string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- Experience: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the above age and Experience is taken as string by default\n",
        "## To change datatype change code to:\n",
        "df_pyspark = spark.read.option('header','true').csv('test1.csv', inferSchema=True)"
      ],
      "metadata": {
        "id": "Z8nJ_Arodjh7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXFHVdBBeJij",
        "outputId": "cd95e169-3233-4f79-d42d-4d82b79e0724"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name : string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way of reading dataset\n",
        "df_pyspark = spark.read.csv('test1.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "7Ha3oIgFeOHX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7LiSSw0euwM",
        "outputId": "39447afc-c39f-4a49-9e09-89a16d8f23d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name : string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1_KNAOFeztx",
        "outputId": "9a72f5e7-19f5-405b-960c-73b383f3fc0d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B311PaI1e8B8",
        "outputId": "02e2636d-6fec-4900-e74a-dd97c63ca9eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name ', 'age', 'Experience']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg4V7QZqfGq6",
        "outputId": "643ed76d-6e8e-4450-f15b-a731fd822d7b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name ='Krish', age=31, Experience=10),\n",
              " Row(Name ='Sudhansu', age=30, Experience=8),\n",
              " Row(Name ='Sunny', age=29, Experience=4)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To pickup just name column\n",
        "df_pyspark.select('Name ') #There is extra space in end of Name since its given so in csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAxi0d_HfRLA",
        "outputId": "ac57c59f-f8cc-4fc2-8499-36f74bf44c29"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name : string]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To pickup all columns and show\n",
        "df_pyspark.select(['Name ', 'age', 'Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeoKrOO0fcAH",
        "outputId": "1031f8a1-af34-498a-cb32-f378d2d191ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+\n",
            "|   Name |age|Experience|\n",
            "+--------+---+----------+\n",
            "|   Krish| 31|        10|\n",
            "|Sudhansu| 30|         8|\n",
            "|   Sunny| 29|         4|\n",
            "+--------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5LRb7OlgJSy",
        "outputId": "a3bebff7-1775-4099-8d16-4495d1563ea2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name ', 'string'), ('age', 'int'), ('Experience', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6dmZkHzgbBt",
        "outputId": "f9bf5b33-7e1a-4faa-94f3-62ee0e798c4d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+-----------------+\n",
            "|summary|Name | age|       Experience|\n",
            "+-------+-----+----+-----------------+\n",
            "|  count|    3|   3|                3|\n",
            "|   mean| null|30.0|7.333333333333333|\n",
            "| stddev| null| 1.0|3.055050463303893|\n",
            "|    min|Krish|  29|                4|\n",
            "|    max|Sunny|  31|               10|\n",
            "+-------+-----+----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add columns in data frame\n",
        "## this is not inplace operation so we need to assign it\n",
        "df_pyspark = df_pyspark.withColumn('Experience after 2 years', df_pyspark['Experience']+2)"
      ],
      "metadata": {
        "id": "n8UtHoz_ggbJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILmqCT3hhDwl",
        "outputId": "ac0f9ae9-5f4e-4099-c49c-c14f7a1294ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+------------------------+\n",
            "|   Name |age|Experience|Experience after 2 years|\n",
            "+--------+---+----------+------------------------+\n",
            "|   Krish| 31|        10|                      12|\n",
            "|Sudhansu| 30|         8|                      10|\n",
            "|   Sunny| 29|         4|                       6|\n",
            "+--------+---+----------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the columns\n",
        "df_pyspark = df_pyspark.drop('Experience after 2 years')"
      ],
      "metadata": {
        "id": "srIC4J0-hdca"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the column\n",
        "## Not a inplace operation\n",
        "df_pyspark.withColumnRenamed('Name ', 'New Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9l_KVX3h1B9",
        "outputId": "e0bf37ce-7452-49b3-a9a1-ae70b710e5ab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+\n",
            "|New Name|age|Experience|\n",
            "+--------+---+----------+\n",
            "|   Krish| 31|        10|\n",
            "|Sudhansu| 30|         8|\n",
            "|   Sunny| 29|         4|\n",
            "+--------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Missing value**"
      ],
      "metadata": {
        "id": "mC5ZG-7YpqJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2 = spark.read.csv('test2.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "_QCqTC7vpeEN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSxXsnhIqYU_",
        "outputId": "e35f35e1-ad37-4d75-e6b2-3a0110a723e6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+----------+------+\n",
            "|   Name | age|Experience|Salary|\n",
            "+--------+----+----------+------+\n",
            "|   Krish|  31|        10| 30000|\n",
            "|Sudhansu|  30|         8| 25000|\n",
            "|   Sunny|  29|         4| 20000|\n",
            "|    Paul|  24|         3| 20000|\n",
            "|  Harsha|  21|         1| 15000|\n",
            "| Shubham|  23|         2| 18000|\n",
            "|  Mahesh|null|      null| 40000|\n",
            "|    null|  34|        10| 38000|\n",
            "|    null|  36|      null|  null|\n",
            "+--------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaaO_dMtqE0U",
        "outputId": "d03ca7cb-5ab8-49cb-fbec-e984907a1757"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name : string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drops all rows that has null\n",
        "## Not inplace opperation\n",
        "df_pyspark2.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfgl5mDXqSLY",
        "outputId": "fb933e61-274b-4caa-db4f-a869f5a1d9b7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+------+\n",
            "|   Name |age|Experience|Salary|\n",
            "+--------+---+----------+------+\n",
            "|   Krish| 31|        10| 30000|\n",
            "|Sudhansu| 30|         8| 25000|\n",
            "|   Sunny| 29|         4| 20000|\n",
            "|    Paul| 24|         3| 20000|\n",
            "|  Harsha| 21|         1| 15000|\n",
            "| Shubham| 23|         2| 18000|\n",
            "+--------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how == any\n",
        "## this will drop rows which has null value in any columns\n",
        "## Not inplace opperation\n",
        "df_pyspark2.na.drop(how='any').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPdTuMnJqwq8",
        "outputId": "ca5bd07b-8ed0-4c3d-e003-d2fd7ea6edbc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+------+\n",
            "|   Name |age|Experience|Salary|\n",
            "+--------+---+----------+------+\n",
            "|   Krish| 31|        10| 30000|\n",
            "|Sudhansu| 30|         8| 25000|\n",
            "|   Sunny| 29|         4| 20000|\n",
            "|    Paul| 24|         3| 20000|\n",
            "|  Harsha| 21|         1| 15000|\n",
            "| Shubham| 23|         2| 18000|\n",
            "+--------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how == any with thresh==2\n",
        "## this will drop rows which has null value in greater than 2 columns\n",
        "## Not inplace opperation\n",
        "df_pyspark2.na.drop(how='any', thresh=2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgfAd8IW73Me",
        "outputId": "370aa1c3-302b-4301-a1db-a5133d1d0bf8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+----------+------+\n",
            "|   Name | age|Experience|Salary|\n",
            "+--------+----+----------+------+\n",
            "|   Krish|  31|        10| 30000|\n",
            "|Sudhansu|  30|         8| 25000|\n",
            "|   Sunny|  29|         4| 20000|\n",
            "|    Paul|  24|         3| 20000|\n",
            "|  Harsha|  21|         1| 15000|\n",
            "| Shubham|  23|         2| 18000|\n",
            "|  Mahesh|null|      null| 40000|\n",
            "|    null|  34|        10| 38000|\n",
            "+--------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset\n",
        "## this will drop rows which has null value in Experience column\n",
        "## Not inplace opperation\n",
        "df_pyspark2.na.drop(how='any', subset=['Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv1wbjkh8EsZ",
        "outputId": "03540dfb-5b7a-4956-d7a5-7e46e8d06f8f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+------+\n",
            "|   Name |age|Experience|Salary|\n",
            "+--------+---+----------+------+\n",
            "|   Krish| 31|        10| 30000|\n",
            "|Sudhansu| 30|         8| 25000|\n",
            "|   Sunny| 29|         4| 20000|\n",
            "|    Paul| 24|         3| 20000|\n",
            "|  Harsha| 21|         1| 15000|\n",
            "| Shubham| 23|         2| 18000|\n",
            "|    null| 34|        10| 38000|\n",
            "+--------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['age', 'Experience', 'Salary'],\n",
        "    outputCols = ['{}_imputed'.format(c) for c in ['age', 'Experience', 'Salary']]\n",
        ").setStrategy('mean')"
      ],
      "metadata": {
        "id": "bAX1hiQ984HX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add imputation cols to df\n",
        "imputer.fit(df_pyspark2).transform(df_pyspark2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtcGmZct9if5",
        "outputId": "fb78382a-8b32-4fc1-b6bb-b574fe9a9bc0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+----------+------+-----------+------------------+--------------+\n",
            "|   Name | age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
            "+--------+----+----------+------+-----------+------------------+--------------+\n",
            "|   Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|Sudhansu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|   Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|    Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|  Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "| Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|  Mahesh|null|      null| 40000|         28|                 5|         40000|\n",
            "|    null|  34|        10| 38000|         34|                10|         38000|\n",
            "|    null|  36|      null|  null|         36|                 5|         25750|\n",
            "+--------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark operations**"
      ],
      "metadata": {
        "id": "j20_Xevi_Xiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3 = spark.read.csv('test3.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "WZKwwI0c__5r"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv4OIwvPAjXg",
        "outputId": "a2af911e-dfce-4d14-dac5-f39647708ea7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+------+\n",
            "|    Name|age|Experience|Salary|\n",
            "+--------+---+----------+------+\n",
            "|   Krish| 31|        10| 30000|\n",
            "|Sudhansu| 30|         8| 25000|\n",
            "|   Sunny| 29|         4| 20000|\n",
            "|    Paul| 24|         3| 20000|\n",
            "|  Harsha| 21|         1| 15000|\n",
            "| Shubham| 23|         2| 18000|\n",
            "+--------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salary of the people less than equal to 20000\n",
        "df_pyspark3.filter('Salary<=20000').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g302ZFyvAne9",
        "outputId": "202a03ce-8c19-41ff-8895-46c03702edd0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Above code can also be written as\n",
        "df_pyspark3.filter(df_pyspark3['Salary']<=20000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKhKvDD5A8Va",
        "outputId": "777bde08-2b19-42a2-de29-af6409b74809"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3.filter((df_pyspark3['Salary']<=20000) & \n",
        "                   (df_pyspark3['Salary']>=15000)).show()\n",
        "## both conditions should be written within bracket orelse will throw error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4ZQ5XwZBYu9",
        "outputId": "b7f7670b-e041-41fb-82b9-792ff2fddf35"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not opertion also known as inverse filter\n",
        "## ~ is the symbol\n",
        "df_pyspark3.filter(~(df_pyspark3['Salary']<=20000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLnIF5dXBoqj",
        "outputId": "68b2d4b6-4e62-4155-b140-7322c2f75625"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+------+\n",
            "|    Name|age|Experience|Salary|\n",
            "+--------+---+----------+------+\n",
            "|   Krish| 31|        10| 30000|\n",
            "|Sudhansu| 30|         8| 25000|\n",
            "+--------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GroupBy and Aggregate functions**"
      ],
      "metadata": {
        "id": "h1af9d2z-LTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4 = spark.read.csv('test4.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "bAi18qOHCd1l"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54kYB8I7Acn3",
        "outputId": "55d5b050-5530-4108-9534-fc396fe6578a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIO2ywFZ-n25",
        "outputId": "215fb276-3bfe-4a26-98da-ed0be138c3f3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Departments: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Groupby\n",
        "## Grouped to find maximum salary\n",
        "df_pyspark4.groupby('Name').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtQv5i5c-tzg",
        "outputId": "6390b090-90e8-438b-b3a5-0f94ad14ac8c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|sum(salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      35000|\n",
            "|    Sunny|      12000|\n",
            "|    Krish|      19000|\n",
            "|   Mahesh|       7000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Groupby departments which gives maximum salary\n",
        "df_pyspark4.groupby('Departments').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A34QHW6i-4B9",
        "outputId": "cc3600d7-b16e-4ff7-b7ed-e85b364f73d5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|sum(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      15000|\n",
            "|    Big Data|      15000|\n",
            "|Data Science|      43000|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Groupby departments to show mean salary\n",
        "df_pyspark4.groupby('Departments').mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLYtgtUs_f4g",
        "outputId": "9ef8234c-2ac2-48e4-d964-a6816a805468"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|avg(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|     7500.0|\n",
            "|    Big Data|     3750.0|\n",
            "|Data Science|    10750.0|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.groupby('Departments').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6Shu8vk_uIV",
        "outputId": "320a4b61-571b-43e6-a972-ebe233615097"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "| Departments|count|\n",
            "+------------+-----+\n",
            "|         IOT|    2|\n",
            "|    Big Data|    4|\n",
            "|Data Science|    4|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find total expenditure\n",
        "df_pyspark4.agg({'Salary': 'sum'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnBRJaJO_yRj",
        "outputId": "852f0a81-c225-4f27-e207-c466bb63fdde"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(Salary)|\n",
            "+-----------+\n",
            "|      73000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qD4kMcv_ACKs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}